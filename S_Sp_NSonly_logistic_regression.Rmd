---
title: "Sensitivity/Specificity Analyses - Canine Leishmaniosis"
author: "Marie Ozanne"
date: "January 30, 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
# library(actuar)
library(coda)
library(ggplot2)
library(R2OpenBUGS)
# library(GGally)
library(summarytools)
```

# Exploratory Analyses

```{r exploratory, echo=FALSE}
setwd("G:/My Drive/Research/Sensitivity_Specificity/")
ss_data <- read.csv("Data/DPPReaderData_cleaned_alldata_final.csv", na.strings = c("NA", "", "."))
ss_data <- ss_data[,!(names(ss_data)%in%c("X", "X.1", "X.2", "X.3"))] ## remove columns with comments only
names(ss_data) <- c(names(ss_data)[1:4], "PCR", "PCR_positive",
                    "DPP", "DPP_positive", "ClinicalStatus")

## For analysis purposes - treat all observations as independent and 'Timepoint' is irrelevant
## Clinical Status (based on 2 or more clinical symptoms): N=negative, A=asymptomatic, S=symptomatic

ss_data[which(ss_data$ClinicalStatus=="AS"),]$ClinicalStatus <- "A" ## replace AS with A for consistency
ss_data[which(ss_data$ClinicalStatus=="SY"),]$ClinicalStatus <- "S" ## replace SY with S for consistency

## drop unused levels from Clinical Status
ss_data$ClinicalStatus <- droplevels(ss_data$ClinicalStatus)

## "F" and "M" erroneously places in Age column
ss_data$Age[which(ss_data$Age=="F")] <- NA
ss_data$Age[which(ss_data$Age=="M")] <- NA
ss_data$Age <- as.numeric(ss_data$Age)

## One pup has PCR as positive - moving this indication to the PCR_positive
## column, which currently has an NA
ss_data[is.na(ss_data$PCR_positive),]$PCR_positive <- "Positive"

## Standardize the levels for PCR_positive
## Current levels: > levels(ss_data$PCR_positive)
#  [1] "BL"                         "BL (single 1:10 well only)" "BL below threshold"   
#  [4] "N"                          "Neg"                        "negative"     
#  [7] "Negative"                   "P"                          "pos"       
# [10] "Pos"                        "positive"                   "Positive"  
### Assume all BL (below limits) are "Negative"
ss_data[ss_data$PCR_positive=="BL",]$PCR_positive <- "Negative"
ss_data[ss_data$PCR_positive=="BL (single 1:10 well only)",]$PCR_positive <- "Negative"
ss_data[ss_data$PCR_positive=="BL below threshold",]$PCR_positive <- "Negative"
ss_data[ss_data$PCR_positive=="N",]$PCR_positive <- "Negative"
ss_data[ss_data$PCR_positive=="Neg",]$PCR_positive <- "Negative"
ss_data[ss_data$PCR_positive=="negative",]$PCR_positive <- "Negative"

### Standardize all positive entries to "Positive"
ss_data[ss_data$PCR_positive=="P",]$PCR_positive <- "Positive"
ss_data[ss_data$PCR_positive=="pos",]$PCR_positive <- "Positive"
ss_data[ss_data$PCR_positive=="Pos",]$PCR_positive <- "Positive"
ss_data[ss_data$PCR_positive=="positive",]$PCR_positive <- "Positive"

## drop unused levels from PCR_positive
ss_data$PCR_positive <- droplevels(ss_data$PCR_positive)

## One pup had "positive" in the PCR column, which should be numeric
## replace with NA - no numerical value available
ss_data$PCR[which(ss_data$PCR=="positive")] <- NA

## Change PCR to numeric
ss_data$PCR <- as.numeric(ss_data$PCR)

## Print summary of data
# summary(ss_data[,!(names(ss_data) %in% c("Timepoint", "ID"))])

## Create new DPP_positive variable based on reader cutoffs (>9.9 is positive)
ss_data$DPP_positive2 <- ifelse(ss_data$DPP > 9.9,
                                c("Positive"), c("Negative"))

## Omit missing values
ss_data_nao <- na.omit(ss_data[,names(ss_data) %in% c("Sex", "Age", "DPP",
                                                      "ClinicalStatus",
                                                      "DPP_positive",
                                                      "PCR_positive",
                                                      "DPP_positive2")])

## Create contingency table for data we are using:
ss_data2 <- ss_data_nao[ss_data_nao$ClinicalStatus!="A",]
ss_data2$DPP_positive2 <- as.factor(ss_data2$DPP_positive2)
table(PCR=ss_data2$PCR_positive, DPP=ss_data2$DPP_positive2)

## Include variable for diagnostically positive (positive on at least one test)
ss_data2$Diagnostically_positive <- rep(NA, nrow(ss_data2))
ss_data2[ss_data2$PCR_positive == "Positive" | ss_data2$DPP_positive2 == "Positive",]$Diagnostically_positive <- "Positive"
ss_data2[ss_data2$PCR_positive == "Negative" & ss_data2$DPP_positive2 == "Negative",]$Diagnostically_positive <- "Negative"
```

# Models

Angela's paper (Toepp et al., 2019, https://doi.org/10.1371/journal.pntd.0007058) uses logistic regression, with age, sex, and variables that have to do with diagnostic tests as explanatory variables. They are something like this:  

**Model A 1:** $logit(\pi_k)=\beta_0+\beta_1Age_k + \beta_2Sex_k + \beta_3 Y_k$, where $Y_k$ is diagnostically positive (as defined in Model 1 below), but for the mom and $\pi_k$ is the probability of disease for individual $k$

**Model A 2:** $logit(\pi_k)=\beta_0+\beta_1Age_k + \beta_2Sex_k + \beta_3 T_{1k} + \beta_4T_{2k}$, where $T_{jk}$ is the result for Test $j$ (as defined in Model 1 below), but for the mom and $\pi_k$ is the probability of disease for individual $k$

Note, these models were fit with a log link function, presumably so that relative risks could be recovered?

We plan to evaluate similar models for our data and to then incorporate sensitivity and specificity of the tests into these models. Then we will compare the model performance to that of other methods. Hopefully we will see an improvement/some details that we miss when we do not include the sensitivity and specificity for the tests.

In all these models, we will assume that the observations are independent.

## Model 1: 

### Data Model

$$
Y_k|T_{1k},T_{2k}\sim Bernoulli\left(P(T_{1k}=1)\cup P(T_{2k}=1) \right)
$$
where $P(T_{1k}=1)\cup P(T_{2k}=1)=P(T_{1k}=1)+P(T_{2k}=1)-P(T_{1k}=1)\times P(T_{2k}=1)$ since we are assuming that the test outcomes are independent.

For the probability of a positive test result for individual $k$ on test $j$,

\begin{align*}
P(T_{jk}=1)&=P(T_{jk}=1 \cap D_k=1) + P(T_{jk}=1 \cap D_k=0)\\
&=P(T_{jk}=1| D_k=1)P(D_k=1) + P(T_{jk}=1| D_k=0)P(D_k=0)\\
&=\underbrace{P(T_{jk}=1| D_k=1)}_{\text{Sensitivity}}P(D_k=1) + \underbrace{[1-P(T_{jk}=0| D_k=0)]}_{1-\text{Specificity}}P(D_k=0)\\
\end{align*}


### Process Model

Now we need a model for the probability of disease for individual $k$ that depends on disease prevalence, and some individual level factors. 

$$
\text{logit}(P(D_k))\sim \text{Normal}(\text{logit}(\pi) + \mathbf{x}_k^T\boldsymbol{\beta} + \epsilon_k, \ \delta^2)
$$

where $\pi$ is the population prevalence of disease, $\mathbf{x}^T_k=(1, Age_k, Sex_k)$, and $\epsilon_k$ is a random individual effect.

### Prior Model

#### Prevalence:

Fix prevalence at 0.075.

#### Other parameters:

$$
\boldsymbol{\epsilon}\sim Normal(\mathbf{0}, \text{ precison}=5 \times 10 ^{-3}*I)
$$

There are individual level random effects $\epsilon_k$, $k=1,...,K$, and they are assumed to be independent.

### OpenBUGS Model 1 Implementation

```{r Open Bugs Model 1, echo=FALSE}
## ranges of sensitivities and specificities
sens.pcr.range <- c(0.839, 0.990)
sens.dpp.range <- c(0.832, 0.930)
spec.pcr.range <- c(0.871, 0.970)
spec.dpp.range <- c(0.682, 0.951)

sens.pcr <- mean(sens.pcr.range)
sens.dpp <- mean(sens.dpp.range)
spec.pcr <- mean(spec.pcr.range)
spec.dpp <- mean(spec.dpp.range)

## range of prevalence for visceral leishmaniasis
prev.range <- c(0.05,0.10)
prev <- mean(prev.range)

## Specify data
y <- 1*(ss_data2$Diagnostically_positive=="Positive")

nind <- nrow(ss_data2)

data <- list(nind=nind,
             y=y,
             sens.pcr=sens.pcr,
             spec.pcr=spec.pcr,
             sens.dpp=sens.dpp,
             spec.dpp=spec.dpp,
             prev=prev
)

## Initialize all prior values
inits <- function(){
  list(eps=rnorm(nind,0,2))
}

## Start MCMC simulation
# sens_spec.sim_m1 <- bugs(data=data, 
#                       inits=inits, ## FIX THIS LINE
#                       model.file="Model1_Logistic_S_Sp_NS_only.txt",
#                       parameters=c("pi.D", "eps"),
#                       n.chains=3, n.iter=10000, n.burnin=5000, 
#                       codaPkg=TRUE, debug=TRUE)
# 
# ## Use coda to read things back into R
# codaobject_m1 <- read.bugs(sens_spec.sim_m1)
# model1_df <- do.call(rbind.data.frame, codaobject_m1)
```

### OpenBUGS Model 1 Disease State Prediction

```{r}
## Set up storage for model results
# pred_df_m1 <- data.frame(obs=1:nind,
#                          pi.D=rep(NA,nind), ## average estimate
#                          SD=rep(NA,nind),
#                          LB=rep(NA,nind), ## 2.5th percentile
#                          UB=rep(NA,nind), ## 97.5th percentile
#                          model_assignment=rep(NA,nind),
#                          Clinical_status=ss_data2$ClinicalStatus,
#                          Diagnostic_status=ss_data2$Diagnostically_positive)
# 
# ## Calculate probabilities of compartment membership for each posterior draw
# pred_df_m1$pi.D <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, mean)
# pred_df_m1$SD <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, sd)
# pred_df_m1$LB <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, quantile, probs=0.025)
# pred_df_m1$UB <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, quantile, probs=0.975)

```


## Model 2: 

The data outcome we are using is "diagnostically positive", meaning that an individual tests positive on at least one diagnostic test. This is what we have used in our other papers and seems to be popular in the literature (add some references to this). In this model, we assume that the two diagnostic tests are independent, and that there is some imprecision in the test results, so we include sensitivity and specificity for each test in the model.

### Data Model

$$
Y_k|T_{1k},T_{2k}\sim Bernoulli\left(P(T_{1k}=1)\cup P(T_{2k}=1) \right)
$$
where $P(T_{1k}=1)\cup P(T_{2k}=1)=P(T_{1k}=1)+P(T_{2k}=1)-P(T_{1k}=1)\times P(T_{2k}=1)$ since we are assuming that the test outcomes are independent.

For the probability of a positive test result for individual $k$ on test $j$,

\begin{align*}
P(T_{jk}=1)&=P(T_{jk}=1 \cap D_k=1) + P(T_{jk}=1 \cap D_k=0)\\
&=P(T_{jk}=1| D_k=1)P(D_k=1) + P(T_{jk}=1| D_k=0)P(D_k=0)\\
&=\underbrace{P(T_{jk}=1| D_k=1)}_{\text{Sensitivity}}P(D_k=1) + \underbrace{[1-P(T_{jk}=0| D_k=0)]}_{1-\text{Specificity}}P(D_k=0)\\
\end{align*}


### Process Model

Now we need a model for the probability of disease for individual $k$ that depends on disease prevalence, and some individual level factors. 

$$
\text{logit}(P(D_k))\sim \text{Normal}(\text{logit}(\pi) + \mathbf{x}_k^T\boldsymbol{\beta} + \epsilon_k, \ \delta^2)
$$

where $\pi$ is the population prevalence of disease, $\mathbf{x}^T_k=(1, Age_k, Sex_k)$, and $\epsilon_k$ is a random individual effect.

### Prior Model

#### Prevalence:
$$
logit(\pi) \sim Normal(\mu_\pi, \sigma^2_\pi)
$$

We have a range for the prevalence of (0.05, 0.10). This corresponds to a range of (`r round(log(0.05)/(1-log(0.05)),4)`, `r round(log(0.10)/(1-log(0.10)),4)`) on the logit scale. 

```{r}
hist(rnorm(10000, mean = log(0.075)/(1-log(0.075)), sd = 0.03),
     main="Logit prevalence prior distribution histogram",
     xlab="logit(prevalence)")
```


#### Other parameters:

$$
\boldsymbol{\epsilon}\sim Normal(\mathbf{0}, \text{ precison}=5 \times 10 ^{-3}*I)
$$

There are individual level random effects $\epsilon_k$, $k=1,...,K$, and they are assumed to be independent.

### OpenBUGS Model 2 Implementation

```{r Open Bugs Model 2, include=FALSE, message=FALSE}
## ranges of sensitivities and specificities
sens.pcr.range <- c(0.839, 0.990)
sens.dpp.range <- c(0.832, 0.930)
spec.pcr.range <- c(0.871, 0.970)
spec.dpp.range <- c(0.682, 0.951)

sens.pcr <- min(sens.pcr.range)
sens.dpp <- min(sens.dpp.range)
spec.pcr <- min(spec.pcr.range)
spec.dpp <- min(spec.dpp.range)

## range of prevalence for visceral leishmaniasis
prev.range <- c(0.05,0.10)
prev <- mean(prev.range)

## Specify data
y <- 1*(ss_data2$Diagnostically_positive=="Positive")

nind <- nrow(ss_data2)

data <- list(nind=nind,
             y=y,
             sens.pcr=sens.pcr,
             spec.pcr=spec.pcr,
             sens.dpp=sens.dpp,
             spec.dpp=spec.dpp,
             prev=prev, 
             prec.lpi=1/0.03
)

## Initialize all prior values
inits <- function(){
  list(lpi=rnorm(1,log(prev)/(1-log(prev)), 0.03),
       b0=rnorm(0,1),
       b1=rnorm(0,1),
       b2=rnorm(0,1),
       eps=rnorm(nind,0,2))
}

## Start MCMC simulation
sens_spec.sim_m2 <- bugs(data=data, 
                      inits=inits, ## FIX THIS LINE
                      model.file="Model2_Logistic_S_Sp_NS_only.txt",
                      parameters=c("pi.D", "lpi", "eps"),
                      n.chains=3, n.iter=10000, n.burnin=5000, 
                      codaPkg=TRUE, debug=TRUE)

## Use coda to read things back into R
codaobject_m2 <- read.bugs(sens_spec.sim_m2)
model2_df <- do.call(rbind.data.frame, codaobject_m2)
```

```{r}
## Graphial summaries of posterior distribtuions
hist(exp(model2_df$lpi)/(1+exp(model2_df$lpi)), main="prevalence", xlab="posterior draws")
abline(v=mean(exp(model2_df$lpi)/(1+exp(model2_df$lpi))), lty="dashed", col="red")

## Numeric summaries of posterior distributions
#boxplot(model2_df[,!(names(model2_df) %in% c("deviance"))])
```

Removing the age and sex parameters made the estimate for prevalence make a lot more sense. Is there are good reason for this? Now the mean prevalence is `r round(mean(exp(model2_df$lpi)/(1+exp(model2_df$lpi))),4)` and the 95% credible interval is: ( `r round(quantile(exp(model2_df$lpi)/(1+exp(model2_df$lpi)), prob=0.025),4)`, `r round(quantile(exp(model2_df$lpi)/(1+exp(model2_df$lpi)), prob=0.975),4)` ).

### OpenBUGS Model 2 Disease State Prediction

```{r m2 prediction , tidy=TRUE}
## Set up storage for model results
pred_df_m2 <- data.frame(obs=1:nind,
                         pi.D=rep(NA,nind), ## average estimate
                         SD=rep(NA,nind),
                         LB=rep(NA,nind), ## 2.5th percentile
                         UB=rep(NA,nind), ## 97.5th percentile
                         model_assignment=rep(NA,nind),
                         Clinical_status=ss_data2$ClinicalStatus,
                         Diagnostic_status=ss_data2$Diagnostically_positive)

## Calculate probabilities of compartment membership for each posterior draw
pred_df_m2$pi.D <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, mean)
pred_df_m2$SD <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, sd)
pred_df_m2$LB <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, 
                       quantile, probs=0.025)
pred_df_m2$UB <- apply(model2_df[,grep("pi.D", names(model2_df))], 2, 
                       quantile, probs=0.975)


summary(pred_df_m2)

## Apply a cut off of point estimate of 0.5; if pi.D > 0.5, classify as S (symptomatic), otherwise as N;
## Summarize in a table (clinical status versus diagnostic status)
table(pred_df_m2[pred_df_m2$pi.D > 0.5,]$Clinical_status, 
      pred_df_m2[pred_df_m2$pi.D > 0.5,]$Diagnostic_status)

## Print summary table of clinical status versus diagnostic status from the original data
table(pred_df_m2$Clinical_status, pred_df_m2$Diagnostic_status)
```

From the first table, we can see that we identify all of the diagnostically positive individuals as having disease. We supplied diagnostic status, so the model is perfectly recovering the diagnostic status, but missing all those that are diagnostically negative but are symptomatic based on clinical status (15 - see second table). It seems like the sensitivity and specificity pieces are not making a difference right now..  







## Model 3: 

The data outcome we are using is "diagnostically positive", meaning that an individual tests positive on at least one diagnostic test. This is what we have used in our other papers and seems to be popular in the literature (add some references to this). In this model, we assume that the two diagnostic tests are independent, and that there is some imprecision in the test results, so we include sensitivity and specificity for each test in the model. We include Sex and Age as explanatory variables, which we didn't do in Model 2. 

### Data Model

$$
Y_k|T_{1k},T_{2k}\sim Bernoulli\left(P(T_{1k}=1)\cup P(T_{2k}=1) \right)
$$
where $P(T_{1k}=1)\cup P(T_{2k}=1)=P(T_{1k}=1)+P(T_{2k}=1)-P(T_{1k}=1)\times P(T_{2k}=1)$ since we are assuming that the test outcomes are independent.

For the probability of a positive test result for individual $k$ on test $j$,

\begin{align*}
P(T_{jk}=1)&=P(T_{jk}=1 \cap D_k=1) + P(T_{jk}=1 \cap D_k=0)\\
&=P(T_{jk}=1| D_k=1)P(D_k=1) + P(T_{jk}=1| D_k=0)P(D_k=0)\\
&=\underbrace{P(T_{jk}=1| D_k=1)}_{\text{Sensitivity}}P(D_k=1) + \underbrace{[1-P(T_{jk}=0| D_k=0)]}_{1-\text{Specificity}}P(D_k=0)\\
\end{align*}


### Process Model

Now we need a model for the probability of disease for individual $k$ that depends on disease prevalence, and some individual level factors. 

$$
\text{logit}(P(D_k))\sim \text{Normal}(\text{logit}(\pi) + \mathbf{x}_k^T\boldsymbol{\beta} + \epsilon_k, \ \delta^2)
$$

where $\pi$ is the population prevalence of disease, $\mathbf{x}^T_k=(1, Age_k, Sex_k)$, and $\epsilon_k$ is a random individual effect.

### Prior Model

#### Prevalence:
$$
logit(\pi) \sim Normal(\mu_\pi, \sigma^2_\pi)
$$

We have a range for the prevalence of (0.05, 0.10). This corresponds to a range of (`r round(log(0.05)/(1-log(0.05)),4)`, `r round(log(0.10)/(1-log(0.10)),4)`) on the logit scale. 

#### Other parameters:
$$
\boldsymbol{\beta}\sim Normal(\boldsymbol{\mu}_\beta, \Sigma_\beta)
$$

We will assume that the regression coefficients are independent, so $\Sigma_\beta$ is a diagonal matrix.

$$
\boldsymbol{\epsilon}\sim Normal(\mathbf{0}, \text{ precison}=5 \times 10 ^{-3}*I)
$$

There are individual level random effects $\epsilon_k$, $k=1,...,K$, and they are assumed to be independent.

### OpenBUGS Model 3 Implementation

```{r Open Bugs Model 3, include=FALSE, message=FALSE}
## ranges of sensitivities and specificities
sens.pcr.range <- c(0.839, 0.990)
sens.dpp.range <- c(0.832, 0.930)
spec.pcr.range <- c(0.871, 0.970)
spec.dpp.range <- c(0.682, 0.951)

sens.pcr <- mean(sens.pcr.range)
sens.dpp <- mean(sens.dpp.range)
spec.pcr <- mean(spec.pcr.range)
spec.dpp <- mean(spec.dpp.range)

## range of prevalence for visceral leishmaniasis
prev.range <- c(0.05,0.10)
prev <- mean(prev.range)

## Specify data
y <- 1*(ss_data2$Diagnostically_positive=="Positive")

nind <- nrow(ss_data2)

Sex2 <- 1*(ss_data2$Sex=="M")
Age <- as.numeric(ss_data2$Age)

data <- list(nind=nind,
             y=y,
             Sex=Sex2,
             Age=Age,
             sens.pcr=sens.pcr,
             spec.pcr=spec.pcr,
             sens.dpp=sens.dpp,
             spec.dpp=spec.dpp,
             prev=prev, 
             prec.lpi=1/0.03
)

## Initialize all prior values
inits <- function(){
  list(lpi=rnorm(1,log(prev)/(1-log(prev)), 0.03),
       b0=rnorm(0,1),
       b1=rnorm(0,1),
       b2=rnorm(0,1),
       eps=rnorm(nind,0,2))
}

## Start MCMC simulation
sens_spec.sim_m3 <- bugs(data=data, 
                      inits=inits, ## FIX THIS LINE
                      model.file="OpenBUGS_S_Sp_NSonly_logistic_regression_Model1.txt",
                      parameters=c("pi.D", "lpi",
                                   "b0", "b1", "b2", "eps",
                                   "y"),
                      n.chains=3, n.iter=10000, n.burnin=5000, 
                      codaPkg=TRUE, debug=TRUE)

## Use coda to read things back into R
codaobject_m3 <- read.bugs(sens_spec.sim_m3)
model3_df <- do.call(rbind.data.frame, codaobject_m3)

```

```{r}
## Graphial summaries of posterior distribtuions
par(mfrow=c(2,3))
hist(model3_df$b0, main="Intercept (b0)", xlab="posterior draws")
abline(v=mean(model3_df$b0), lty="dashed", col="red")
hist(model3_df$b1, main="Sex=Male (b1)", xlab="posterior draws")
abline(v=mean(model3_df$b1), lty="dashed", col="red")
hist(model3_df$b2, main="Age (b2)", xlab="posterior draws")
abline(v=mean(model3_df$b2), lty="dashed", col="red")
hist(exp(model3_df$lpi)/(1+exp(model3_df$lpi)), main="Logit(prevalence)", xlab="posterior draws")
abline(v=mean(exp(model3_df$lpi)/(1+exp(model3_df$lpi))), lty="dashed", col="red")

## Numeric summaries of posterior distributions
#boxplot(model3_df[,!(names(model3_df) %in% c("deviance"))])
```

On this run, the mean prevalence is `r round(mean(exp(model3_df$lpi)/(1+exp(model3_df$lpi))),3)`, which is outside the range that we have from the literature: (0.05, 0.10). Why is this so high? Should there be an intercept in this model? If we add in the estimate for the intercept and claim that this is the mean estimate for the disease prevalence (which I don't think makes any sense), the resulting estimate is: `r round(mean(exp(model3_df$lpi+model3_df$b0)/(1+exp(model3_df$lpi+model3_df$b0))),3)`, which still seems to be too high, but not nearly as bad. 

Options: 

(1) Simplify the model by fixing prevalence, and see what we get.
(2) Change the prior on prevalence? Make it less vague?

### OpenBUGS Model 3 Disease State Prediction

```{r}
## Set up storage for model results
pred_df_m3 <- data.frame(obs=1:nind,
                         pi.D=rep(NA,nind), ## average estimate
                         SD=rep(NA,nind),
                         LB=rep(NA,nind), ## 2.5th percentile
                         UB=rep(NA,nind), ## 97.5th percentile
                         model_assignment=rep(NA,nind),
                         Clinical_status=ss_data2$ClinicalStatus,
                         Diagnostic_status=ss_data2$Diagnostically_positive)

## Calculate probabilities of compartment membership for each posterior draw
pred_df_m3$pi.D <- apply(model3_df[,grep("pi.D", names(model3_df))], 2, mean)
pred_df_m3$SD <- apply(model3_df[,grep("pi.D", names(model3_df))], 2, sd)
pred_df_m3$LB <- apply(model3_df[,grep("pi.D", names(model3_df))], 2, quantile, probs=0.025)
pred_df_m3$UB <- apply(model3_df[,grep("pi.D", names(model3_df))], 2, quantile, probs=0.975)

summary(pred_df_m3)

## Apply a cut off of point estimate of 0.5; if pi.D > 0.5, classify as S (symptomatic), otherwise as N;
## Summarize in a table (clinical status versus diagnostic status)
table(pred_df_m3[pred_df_m3$pi.D > 0.5,]$Clinical_status, 
      pred_df_m3[pred_df_m3$pi.D > 0.5,]$Diagnostic_status)

## Print summary table of clinical status versus diagnostic status from the original data
table(pred_df_m3$Clinical_status, pred_df_m3$Diagnostic_status)
```

This model fails to identify anyone as being diseased given diagnostic status. Why might this be? It has three additional parameters (relative to Model 2). 